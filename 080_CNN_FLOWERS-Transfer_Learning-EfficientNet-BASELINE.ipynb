{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHK6DyunSbs4"
   },
   "source": [
    "# Flowers CNN - SOFTMAX - EfficientNet\n",
    "\n",
    "**Description:** Classify cats and dogs with a simple Convolutional Network<br>\n",
    "                This version is programmed as a multiclass classifier with a softmax function in last layer <br>\n",
    "                This version uses EfficientNet a very large (and efficient) network that is the market standard <br>\n",
    "                 \n",
    "**Dataset:** Tensorflow Flowers dataset 5 classes\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # to avoid warning messages\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import ReLU, Dense, Softmax, Rescaling, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.stderr = open('err.txt', 'w')\n",
    "\n",
    "AUGMENTATION = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Identifying GPU to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "devices = device_lib.list_local_devices()\n",
    "gpu_devices = [device for device in devices if device.device_type == 'GPU']\n",
    "for gpu in gpu_devices:\n",
    "    print('Using', gpu.physical_device_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyperparameters\n",
    "training_epochs = 50\n",
    "lr = 1e-5\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "ds, ds_info = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split='train',\n",
    "    with_info=True,\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(4):\n",
    "    print(\"Shape:\", example['image'].shape, \"Label:\", example['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 4\n",
    "COLS = 4\n",
    "plt.figure(figsize=(8,8))\n",
    "for i, example in enumerate(ds.take(ROWS*COLS)):\n",
    "    image = example['image']\n",
    "    label = example['label']\n",
    "    name = ds_info.features['label'].int2str(label)\n",
    "    plt.subplot(ROWS, COLS, i+1)\n",
    "    plt.title(\"{} ({})\".format(name, label))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_, ds_valid_ = tfds.load(\n",
    "    'tf_flowers',\n",
    "    as_supervised=True,\n",
    "    split=['train[:75%]', 'train[75%:]'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = [img_height, img_width]\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, size=SIZE)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE # TensorFlow can automatically apply optimizations to some parts of the pipeline\n",
    "NUM_TRAINING_IMAGES = ds_info.splits['train'].num_examples\n",
    "SHUFFLE_BUFFER =  NUM_TRAINING_IMAGES // 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = (ds_train_\n",
    "            .map(preprocess, AUTO) # do any (non-random) preprocessing first\n",
    "            .cache() # and then keep the images in memory cache\n",
    "            .shuffle(SHUFFLE_BUFFER) # randomize image order while training\n",
    "            .batch(BATCH_SIZE)\n",
    "            .map(augment, AUTO) # put (random) augmentation after batching\n",
    "            .prefetch(AUTO) # use CPU to load data while TPU is working\n",
    ")\n",
    "\n",
    "validation_dataset = (ds_valid_\n",
    "            .map(preprocess, AUTO)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .cache()\n",
    "            .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Network Architecture Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "model = Sequential()\n",
    "\n",
    "efnModel = EfficientNetB7(weights = 'imagenet', \n",
    "                          input_shape = (img_height, img_width, 3), \n",
    "                       include_top = False)\n",
    "                          \n",
    ">>>>> WRITE HERE YOUR CODE EfficientNet or VGG\n",
    ">>>>> Carful with the loss use sparse categorical as it is encoded like that\n",
    "\n",
    "# decay is included for backward compatibility to allow time inverse decay of lr\n",
    "opt1 = RMSprop(learning_rate=lr, decay=1e-6)\n",
    "opt2 = Adam(learning_rate=lr) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = opt1, \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting callbakcs\n",
    "\n",
    "initial_learning_rate = 0.015\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    min_delta=0.0000001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor = 0.2,                                     \n",
    "    patience = 10,                                   \n",
    "    min_delt = 0.0000001,                                \n",
    "    cooldown = 0,                               \n",
    "    verbose = 1\n",
    ") \n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=training_epochs, validation_data=validation_dataset, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZqvC9UJlWc2"
   },
   "source": [
    "#### **Evaluate the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss, accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='orange')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the validation dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in validation_dataset:\n",
    "    y_true.extend(labels.numpy())  # True labels \n",
    "    preds = model.predict(images, verbose=0)  # Model predictions\n",
    "#    y_pred.extend((preds > 0.5).astype(int))   This is for binary\n",
    "    y_pred.extend(np.argmax(preds, axis = 1))\n",
    "\n",
    "y_true = np.argmax(y_true, axis = 1)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(y_true.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\")\n",
    "plt.title(\"Confusion Matrix CNN Binary Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final accuracy\n",
    "final_accuracy = history.history['acc'][-1]  # Last epoch training accuracy\n",
    "final_val_accuracy = history.history['val_acc'][-1] \n",
    "\n",
    "print(f\"Final Training Accuracy: {final_accuracy}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GrFpZXNQB9FW",
    "OpFqg-R1g9n6"
   ],
   "name": "image_classification_part2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL-Keras",
   "language": "python",
   "name": "dl-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
