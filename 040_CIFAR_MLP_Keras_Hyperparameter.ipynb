{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CIFAR10 MLP Hyperparameter exploration example using Scikit**\n",
    "\n",
    "This is an example of Hyperparameter setting for MNIST MLP with Keras and Scikit. <br>\n",
    "Uncomment cell #1 to use it in COLAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install random\n",
    "#!pip install matplotlib\n",
    "#!pip install tensorflow==2.17.1\n",
    "#!pip install keras==3.6.0\n",
    "#!pip pandas as pd\n",
    "#!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XmduteTzhmVH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740085170.451571  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085170.479480  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085170.479520  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085170.612032  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085170.612087  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085170.612117  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465271  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465361  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465377  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465520  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465539  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465550  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.465975  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1740085172.466004  684184 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740085173.578160  684267 service.cc:146] XLA service 0x7fdd44009720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740085173.578187  684267 service.cc:154]   StreamExecutor device (0): NVIDIA T600 Laptop GPU, Compute Capability 7.5\n",
      "I0000 00:00:1740085174.380407  684267 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import ReLU, Dense, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import sys\n",
    "sys.stderr = open('err.txt', 'w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Identify GPU to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "devices = device_lib.list_local_devices()\n",
    "gpu_devices = [device for device in devices if device.device_type == 'GPU']\n",
    "for gpu in gpu_devices:\n",
    "    print('Using', gpu.physical_device_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Search Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_size1'  : [512,1024, 2048],\n",
    "    'hidden_size2'  : [512, 1024],\n",
    "    'activation_pr': ['relu'],\n",
    "    'optimizer_pr' : ['adam'],\n",
    "    'lrate'        : [0.0001, 0.0001],\n",
    "    'batch_size'   : [32],\n",
    "    'loss_pr'      : ['categorical_crossentropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rxswekI1hmXw"
   },
   "outputs": [],
   "source": [
    "# Parameters not optimized\n",
    "\n",
    "num_classes = 10  # this is the number of digits\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data preparation and processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 3072)\n",
      "3072 (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "type(x_train)                # data loaded in numpy arrays\n",
    "print(x_train.shape, y_train.shape)\n",
    "label_dict = {0: \"airplane\",\n",
    "                     1: \"automobile\",\n",
    "                     2: \"bird\",\n",
    "                     3: \"cat\",\n",
    "                     4: \"deer\",\n",
    "                     5: \"dog\",\n",
    "                     6: \"frog\",\n",
    "                     7: \"horse\",\n",
    "                     8: \"ship\",\n",
    "                     9: \"truck\"}\n",
    "\n",
    "# reshape images to RGB scale with width & height are size 32\n",
    "X_train = x_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = x_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "# normalization to avoid gradient explode or vanish\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# convert class into one hot encoder\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "print(X_test.shape)\n",
    "input_shape = X_test.shape[1]\n",
    "print(input_shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MLP Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLP(optimizer_pr = 'adam', loss_pr='MeanSquaredError', activation_pr='relu', \n",
    "               lrate=0.001, hidden_size1=64, hidden_size2=64):\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(hidden_size1, activation=activation_pr)(inputs)\n",
    "    x = Dense(hidden_size2, activation=activation_pr)(inputs)\n",
    "    x = Dense(10)(x)\n",
    "    output = Softmax()(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    if optimizer_pr == 'adam':\n",
    "        opt = Adam(learning_rate=lrate)\n",
    "    if optimizer_pr ==  'rmsprop':\n",
    "        opt = RMSprop(learning_rate=lrate)\n",
    "    model.compile(optimizer= opt, loss = loss_pr, metrics=['accuracy'])\n",
    "              \n",
    "    return model\n",
    "\n",
    "# Configure early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=5,         # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,           # Log when training is stopped\n",
    "    min_delta=0.001,\n",
    "    mode='min',          # Stop training when the monitored quantity has stopped decreasing\n",
    "    restore_best_weights = True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shorten the exploration to 5 epochs to reduce overall exploration time\n",
    "\n",
    "model = KerasClassifier(build_fn=create_MLP, hidden_size1=64, hidden_size2=64, lrate=0.001, optimizer_pr = 'adam',\n",
    "                        loss_pr='categorical_crossentropy', activation_pr='relu', batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.492 total time= 1.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.501 total time= 1.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.501 total time= 2.6min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.494 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.502 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.515 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.507 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=512, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.498 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.506 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.486 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.501 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.502 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.503 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.498 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.504 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=1024, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.503 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.497 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.504 total time= 2.9min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.505 total time= 2.8min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=512, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.502 total time= 2.8min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.508 total time= 2.8min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.498 total time= 2.8min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 1/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.502 total time= 3.0min\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[CV 2/2] END activation_pr=relu, batch_size=32, hidden_size1=2048, hidden_size2=1024, loss_pr=categorical_crossentropy, lrate=0.0001, optimizer_pr=adam;, score=0.491 total time= 3.3min\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose = 3)\n",
    "grid_result = grid.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                 callbacks=[early_stopping], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.50854 using {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 512, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.4965 (+/- 0.0046) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 512, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.4975 (+/- 0.0032) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 512, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5085 (+/- 0.0061) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 512, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5025 (+/- 0.0048) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 512, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.4957 (+/- 0.0101) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 1024, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5013 (+/- 0.0006) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 1024, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5004 (+/- 0.0026) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 1024, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5039 (+/- 0.0004) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 1024, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5007 (+/- 0.0035) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 2048, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5036 (+/- 0.0013) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 2048, 'hidden_size2': 512, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.5029 (+/- 0.0052) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 2048, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n",
      "Accuracy: 0.4963 (+/- 0.0053) with params: {'activation_pr': 'relu', 'batch_size': 32, 'hidden_size1': 2048, 'hidden_size2': 1024, 'loss_pr': 'categorical_crossentropy', 'lrate': 0.0001, 'optimizer_pr': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Accuracy: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "# Detailed results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"Accuracy: {mean:.4f} (+/- {std:.4f}) with params: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "keras               3.6.0\n",
      "matplotlib          3.9.2\n",
      "numpy               1.26.4\n",
      "scikeras            0.13.0\n",
      "session_info        1.0.0\n",
      "sklearn             1.5.2\n",
      "tensorflow          2.17.1\n",
      "-----\n",
      "IPython             8.28.0\n",
      "jupyter_client      8.6.3\n",
      "jupyter_core        5.7.2\n",
      "-----\n",
      "Python 3.12.3 (main, Jan 17 2025, 18:03:48) [GCC 13.3.0]\n",
      "Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "-----\n",
      "Session information updated at 2025-02-20 23:12\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL-Keras",
   "language": "python",
   "name": "dl-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
